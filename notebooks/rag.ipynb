{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40762200-a8a0-40b1-8830-7270bb4135f6",
   "metadata": {},
   "source": [
    "from example https://github.com/reichenbch/RAG-examples/blob/main/LangChain%20LLamaIndex%20RAG.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5a7b05-4447-41d3-80f8-595a7ec06a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/sulcan/Documents/ipac-logbook/code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a4aad6-24b7-44e2-8a97-4195e0e41dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from hugginface_wrapper import MistralLLM\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6899d7cc-09b0-49dc-aaf8-064a1d4408a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/sulcan/Documents/malapa/data/abstracts.csv')\n",
    "abstracts = list(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0299fc7-b50b-45c9-8561-ff6e98338d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c82e0dd501d4194abcfda872260fc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\") \n",
    "vector_store = FAISS.from_texts(abstracts, embeddings)\n",
    "vector_store.save_local(\"../data/faiss_doc_idx\")\n",
    "docs = vector_store.similarity_search(\"What is anomaly detection?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e7621d-226d-4329-9dd6-e032a2b7a920",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/chat/mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7b198c-9e2e-4d7a-936a-fb305a1f0081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langchain_core.messages import HumanMessage\\nmessages = [HumanMessage(content=\"knock knock\")]\\nllm.invoke(messages)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = MistralLLM(max_new_tokens = 128)\n",
    "\n",
    "'''\n",
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"knock knock\")]\n",
    "llm.invoke(messages)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1680768a-16d0-4710-95cf-78f05103584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.gopenai.com/unveiling-retrieval-qa-and-load-qa-chain-for-langchain-question-answering-42de13c1de84\n",
    "chain = load_qa_chain(llm, chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318f6600-d64c-446f-a116-aa572c20ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"English\"\n",
    "template = \"\"\"I want you to act as a question answering bot which uses the context mentioned and answer in a concise manner and doesn't make stuff up.\n",
    "            You will answer question based on the context - {context}.\n",
    "            You will create content in \"\"\" + str(language) + \"\"\"language.\n",
    "            Question: {question}\n",
    "            Answer:\n",
    "            \"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vector_store.as_retriever(), \n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e91d8e-83a7-4681-b688-eb9d0398467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": \"Is there someone talking about anomaly detection\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b429321-4236-4fa4-8873-3a5a9c645543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] I want you to act as a question answering bot which uses the context mentioned and answer in a concise manner and doesn't make stuff up.\n",
      "            You will answer question based on the context - Machine Learning (ML) has gained significant prominence in the field of engineering due to its adaptability and versatility. An example of its practical application is in anomaly detection, which serves the fundamental purpose of providing a binary response to the question, \"Has an issue arisen?\". Most machine learning and anomaly detection projects strive to provide generalisable solutions that are robust to changes within systems. This is of particular importance when components that are subject to anomalies are upgraded; the behaviour and values in the system remain unchanged, but the data resolution may be higher, and anomalies may manifest themselves in slightly different ways. An ideal ML solution would be able to detect anomalies as accurately in this new system as in the old one with minimal intervention or retraining. However, cases like the one described do not happen frequently and therefore it is difficult to test generalisability of models. The methane moderator of Target Station 1 at ISIS originally had an anomaly detection model. Following an upgrade, this work will explore how well the original model generalizes for the system such that it can be easily adapted from the old version of the moderator to the newer one. The original model used a combination of a 1 dimensional convolutional neural network binary classifier and a hypothesis test. The outputs of those two models would be used in a weighted sum. We will also investigate other methods to improve the generalizability that will allow for more flexibility with minimal changes or training when adapting the model from an old training set to a newer one.\n",
      "\n",
      "Particle accelerators are made up of thousands of components with many pieces of equipment running at their peak power. As a consequence, particle accelerators can fault and abort operations for numerous reasons. In order to avoid these faults, we apply uncertainty aware Machine Learning (ML) based anomaly prediction techniques. We predict any unusual behavior and perform preemptive actions in order to improve the total availability of particle accelerators. One of the challenges with application of ML on particle accelerators is the variability of the data due to changes in the system configurations. To address this, we employ conditional models. In addition, distance-based uncertainty awareness allows us to decide when a model need to be re-trained/tuned for continual learning with drift in the data. In this talk, we present an overview of various ML use-cases being explored at Spallation Neutron Source (SNS) accelerator to improve efficiency. Further, we present errant beam prognostics in detail including experimental setup, data collection, curation, model training, evaluation and deployment results. In addition, we present comparison between semi-supervised (conditional variational auto-encoder) and supervised learning (conditional Siamese model) methods for anomaly detection at SNS.\n",
      "\n",
      "The CERN SPS Beam Dump System (SBDS) disposes the beam in the SPS at end of cycled operation or in case of machine malfunctioning, with its kicker magnets deviating the beam to an absorber block and diluting the particle density. This is a critical system, as its malfunctioning can lead to absorber block degradation, unwanted activation of the surroundings or even damage to the vacuum chamber. We develop an online anomaly detection system for the SBDS based on real-time images of a beam screen device. Crucially, the model must accurately classify these images despite being trained on an unlabelled dataset and one in which anomalous samples are uncommon. We show this can be achieved with a convolutional autoencoder and by leveraging the quality of its reconstructions. This work improves the safety of operating the SPS and contributes towards the goal of automating the operation of particle accelerators.\n",
      "\n",
      "The Collider-Accelerator Departmentâ€™s (C-AD) Controls Group at Brookhaven National Laboratory produces and implements tools to analyze data after magnet quench events. Diodes are used in the circuitry to protect quenching magnets from damage.  Intermittently failing diodes can be difficult to identify as they may not always impact beam. Accelerator physicists have studied the voltage tap shutoff curves at various times after a failure, identifying specific time zones over which a derivative may be calculated to detect an anomaly.  Anomaly detection and clustering models show promise by detecting negative events and outliers in datasets.  Using machine learning modeling algorithms, an automated analysis for each power supply based on the voltage tap data can be applied which will help to efficiently identify faulty diodes and limit the number of false positives reported.  This could potentially lead to faster recovery times as well as help avoid equipment damage..\n",
      "            You will create content in Englishlanguage.\n",
      "            Question: Is there someone talking about anomaly detection\n",
      "            Answer:\n",
      "             [/INST] Yes, the context discusses several applications of machine learning for anomaly detection in various systems, including particle accelerators and a beam dump system for particle accelerators.\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2ebd4-c388-44c1-95b0-5f3a13e10e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
