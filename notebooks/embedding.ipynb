{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563bed01-8ffe-46c2-a095-890be6fa7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers.util import cos_sim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import re\n",
    "import pickle, gzip\n",
    "import sys\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sys.path.insert(0,'/home/sulcan/Documents/ipac-logbook/code/')\n",
    "from mmd import *\n",
    "\n",
    "i = 0\n",
    "\n",
    "data_folder = '/home/sulcan/Documents/ipac-logbook/data/data_acc/'\n",
    "model_folder = f'/home/sulcan/Documents/ipac-logbook/models/simcse/{i}'\n",
    "\n",
    "\n",
    "folders = [f'{data_folder}/arxiv/',\\\n",
    "           f'{data_folder}/jacow/',\\\n",
    "           f'{data_folder}/books/']\n",
    "\n",
    "files = []\n",
    "for folder in folders:\n",
    "    files.extend(glob(folder + '*.mmd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b54d32-5856-4e3a-96b1-a84ed7c8b812",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b6e186-99e1-4663-aa61-2000c463d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # loading data\n",
    "    print('loading data...')\n",
    "    data_mmd = {}\n",
    "    for file in tqdm(sorted(files)):\n",
    "        with open(file, 'r') as f:\n",
    "            data_mmd[file] = f.read()\n",
    "    print('... data loaded')\n",
    "    \n",
    "    print('preparing data ...')\n",
    "    # preparing equations and removing tables\n",
    "    data_mmd = prepare_mmd_eqations_and_tables_for_simcse(data_mmd)\n",
    "    print('... data prepared')\n",
    "    \n",
    "    print('chunking sentences ...')\n",
    "    # chunking sentences\n",
    "    train_sentences = []\n",
    "    for k in tqdm(data_mmd):\n",
    "        train_sentences.extend(sent_tokenize(data_mmd[k]))\n",
    "    \n",
    "    with open(f'{data_folder}/simcse_prepared_data.pickle.gzip','wb') as f:\n",
    "        pickle.dump({'data_mmd' : data_mmd, 'train_sentences' : train_sentences}, f)\n",
    "    print('...sentences chunked.')\n",
    "    \n",
    "else:\n",
    "    '''\n",
    "    with open(f'{data_folder}/simcse_prepared_data.pickle.gzip','rb') as f:\n",
    "        data_mmd = pickle.load(f)\n",
    "    '''\n",
    "    with open(f'{data_folder}/simcse_prepared_data.pickle.gzip','rb') as f:\n",
    "        data = pickle.load(f)# \n",
    "        data_mmd = data['data_mmd']\n",
    "        train_sentences = data['train_sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5361e6-3179-4aba-83f7-1afed6bc3970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6231288/6231288 [00:21<00:00, 294874.24it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90872d23b284bb08fc7658e0712dbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab82ed740b54b5f941f91b000605c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/32455 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define your sentence transformer model using CLS pooling\n",
    "model_name = \"allenai/scibert_scivocab_cased\"\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=128)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device = 'cuda:1')\n",
    "\n",
    "# Convert train sentences to sentence pairs\n",
    "train_data = [InputExample(texts=[s, s]) for s in tqdm(train_sentences)]\n",
    "\n",
    "# DataLoader to batch your data\n",
    "train_dataloader = DataLoader(train_data, batch_size=192, shuffle=True)\n",
    "\n",
    "# Use the denoising auto-encoder loss\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "\n",
    "# Call the fit method\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)], epochs=5, show_progress_bar=True\n",
    ")\n",
    "\n",
    "# model.save(\"output/simcse-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19282c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    model.save(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4bd51b-5d3d-4c52-9e0f-477a1054d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = model.encode(train_sentences)\n",
    "cos_sim(e,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ece03b-7a84-43b1-8822-da9443c18abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
